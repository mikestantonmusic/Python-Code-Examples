{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import, Start Pyspark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading https://files.pythonhosted.org/packages/d1/48/cc321e742a93320c681b3c7a9fd405d518c6326c89da3d67e35b9868e941/pyspark-3.3.1.tar.gz (281.4MB)\n",
      "Collecting py4j==0.10.9.5 (from pyspark)\n",
      "  Downloading https://files.pythonhosted.org/packages/86/ec/60880978512d5569ca4bf32b3b4d7776a528ecf4bca4523936c98c92a3c8/py4j-0.10.9.5-py2.py3-none-any.whl (199kB)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py): started\n",
      "  Building wheel for pyspark (setup.py): finished with status 'done'\n",
      "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845519 sha256=139a09e7e8f01ba4797691767b33278924125f2a95688a4c94849e9eb4945cb1\n",
      "  Stored in directory: C:\\Users\\mstan\\AppData\\Local\\pip\\Cache\\wheels\\e5\\cc\\9a\\0c20ee0940a9e80053edfe2270daee438f36037e1ff041c0ec\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>genre</th>\n",
       "      <th>listeners</th>\n",
       "      <th>streams</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roses</td>\n",
       "      <td>rap</td>\n",
       "      <td>351.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jupiter</td>\n",
       "      <td>rap</td>\n",
       "      <td>135.0</td>\n",
       "      <td>6518.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fire</td>\n",
       "      <td>rock</td>\n",
       "      <td>642.0</td>\n",
       "      <td>2491.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>venom</td>\n",
       "      <td>rock</td>\n",
       "      <td>786.0</td>\n",
       "      <td>3714.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sky</td>\n",
       "      <td>classical</td>\n",
       "      <td>124.0</td>\n",
       "      <td>1142.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>danger</td>\n",
       "      <td>classical</td>\n",
       "      <td>123.0</td>\n",
       "      <td>6548.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ocean</td>\n",
       "      <td>classical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>364.0</td>\n",
       "      <td>3145.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>420.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     album      genre  listeners  streams  rating\n",
       "0    roses        rap      351.0   1138.0     6.0\n",
       "1  jupiter        rap      135.0   6518.0    99.0\n",
       "2     fire       rock      642.0   2491.0     7.0\n",
       "3    venom       rock      786.0   3714.0    15.0\n",
       "4      sky  classical      124.0   1142.0    18.0\n",
       "5   danger  classical      123.0   6548.0    99.0\n",
       "6    ocean  classical        NaN      NaN    20.0\n",
       "7      NaN        NaN      364.0   3145.0    17.0\n",
       "8      NaN        NaN      420.0      NaN     NaN"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/basic_csv_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://LAPTOP-H9J6OCAV.myfiosgateway.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>practice</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1f65c6c2948>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# View Data in Pyspark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+\n",
      "|  album|    genre|listeners|streams|rating|\n",
      "+-------+---------+---------+-------+------+\n",
      "|  roses|      rap|      351|   1138|     6|\n",
      "|jupiter|      rap|      135|   6518|    99|\n",
      "|   fire|     rock|      642|   2491|     7|\n",
      "|  venom|     rock|      786|   3714|    15|\n",
      "|    sky|classical|      124|   1142|    18|\n",
      "| danger|classical|      123|   6548|    99|\n",
      "|  ocean|classical|     null|   null|    20|\n",
      "|   null|     null|      364|   3145|    17|\n",
      "|   null|     null|      420|   null|  null|\n",
      "+-------+---------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('data/basic_csv_data.csv', inferSchema = True)\n",
    "\n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- album: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- listeners: integer (nullable = true)\n",
      " |-- streams: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['album', 'genre', 'listeners', 'streams', 'rating']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(album='roses', genre='rap', listeners=351, streams=1138, rating=6),\n",
       " Row(album='jupiter', genre='rap', listeners=135, streams=6518, rating=99)]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "|  album|listeners|\n",
      "+-------+---------+\n",
      "|  roses|      351|\n",
      "|jupiter|      135|\n",
      "|   fire|      642|\n",
      "|  venom|      786|\n",
      "|    sky|      124|\n",
      "| danger|      123|\n",
      "|  ocean|     null|\n",
      "|   null|      364|\n",
      "|   null|      420|\n",
      "+-------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.select(['album','listeners']).show() # fyi slicing will not work, seems to work without brackets \n",
    "# TODO check documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('album', 'string'),\n",
       " ('genre', 'string'),\n",
       " ('listeners', 'int'),\n",
       " ('streams', 'int'),\n",
       " ('rating', 'int')]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pyspark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+---------+-----------------+-----------------+------------------+\n",
      "|summary| album|    genre|        listeners|          streams|            rating|\n",
      "+-------+------+---------+-----------------+-----------------+------------------+\n",
      "|  count|     7|        7|                8|                7|                 8|\n",
      "|   mean|  null|     null|          368.125|           3528.0|            35.125|\n",
      "| stddev|  null|     null|246.8831056535519|2262.824562355642|39.740003235315136|\n",
      "|    min|danger|classical|              123|             1138|                 6|\n",
      "|    max| venom|     rock|              786|             6548|                99|\n",
      "+-------+------+---------+-----------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing with Pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+\n",
      "|  album|    genre|listeners|streams|rating|\n",
      "+-------+---------+---------+-------+------+\n",
      "|  roses|      rap|      351|   1138|     6|\n",
      "|jupiter|      rap|      135|   6518|    99|\n",
      "|   fire|     rock|      642|   2491|     7|\n",
      "|  venom|     rock|      786|   3714|    15|\n",
      "|    sky|classical|      124|   1142|    18|\n",
      "| danger|classical|      123|   6548|    99|\n",
      "|  ocean|classical|     null|   null|    20|\n",
      "|   null|     null|      364|   3145|    17|\n",
      "+-------+---------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='any', thresh = 2).show() # any is the default of how, \n",
    "# thresh is the number of non null values to be required in a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+\n",
      "|  album|    genre|listeners|streams|rating|\n",
      "+-------+---------+---------+-------+------+\n",
      "|  roses|      rap|      351|   1138|     6|\n",
      "|jupiter|      rap|      135|   6518|    99|\n",
      "|   fire|     rock|      642|   2491|     7|\n",
      "|  venom|     rock|      786|   3714|    15|\n",
      "|    sky|classical|      124|   1142|    18|\n",
      "| danger|classical|      123|   6548|    99|\n",
      "|  ocean|classical|     null|   null|    20|\n",
      "|   null|     null|      364|   3145|    17|\n",
      "|   null|     null|      420|   null|  null|\n",
      "+-------+---------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(how='all').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+\n",
      "|  album|    genre|listeners|streams|rating|\n",
      "+-------+---------+---------+-------+------+\n",
      "|  roses|      rap|      351|   1138|     6|\n",
      "|jupiter|      rap|      135|   6518|    99|\n",
      "|   fire|     rock|      642|   2491|     7|\n",
      "|  venom|     rock|      786|   3714|    15|\n",
      "|    sky|classical|      124|   1142|    18|\n",
      "| danger|classical|      123|   6548|    99|\n",
      "|  ocean|classical|     null|   null|    20|\n",
      "|   null|     null|      364|   3145|    17|\n",
      "+-------+---------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.na.drop(subset='rating').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to replace nans with the mean for each column\n",
    "\n",
    "from pyspark.ml.feature import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(\n",
    "    inputCols = ['listeners', 'streams', 'rating'],\n",
    "    outputCols = [\"{}_imputed\".format(c) for c in ['listeners', 'streams', 'rating']],\n",
    "    ).setStrategy('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = imputer.fit(df_pyspark).transform(df_pyspark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+-----------------+---------------+--------------+\n",
      "|  album|    genre|listeners|streams|rating|listeners_imputed|streams_imputed|rating_imputed|\n",
      "+-------+---------+---------+-------+------+-----------------+---------------+--------------+\n",
      "|  roses|      rap|      351|   1138|     6|              351|           1138|             6|\n",
      "|jupiter|      rap|      135|   6518|    99|              135|           6518|            99|\n",
      "|   fire|     rock|      642|   2491|     7|              642|           2491|             7|\n",
      "|  venom|     rock|      786|   3714|    15|              786|           3714|            15|\n",
      "|    sky|classical|      124|   1142|    18|              124|           1142|            18|\n",
      "| danger|classical|      123|   6548|    99|              123|           6548|            99|\n",
      "|  ocean|classical|     null|   null|    20|              368|           3528|            20|\n",
      "|   null|     null|      364|   3145|    17|              364|           3145|            17|\n",
      "|   null|     null|      420|   null|  null|              420|           3528|            35|\n",
      "+-------+---------+---------+-------+------+-----------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----------------+---------------+--------------+\n",
      "|  album|    genre|listeners_imputed|streams_imputed|rating_imputed|\n",
      "+-------+---------+-----------------+---------------+--------------+\n",
      "|  roses|      rap|              351|           1138|             6|\n",
      "|jupiter|      rap|              135|           6518|            99|\n",
      "|   fire|     rock|              642|           2491|             7|\n",
      "|  venom|     rock|              786|           3714|            15|\n",
      "|    sky|classical|              124|           1142|            18|\n",
      "| danger|classical|              123|           6548|            99|\n",
      "|  ocean|classical|              368|           3528|            20|\n",
      "|   null|     null|              364|           3145|            17|\n",
      "|   null|     null|              420|           3528|            35|\n",
      "+-------+---------+-----------------+---------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drop_cols_list = ['listeners','streams','rating']\n",
    "\n",
    "for col in drop_cols_list:\n",
    "    df_pyspark = df_pyspark.drop(col)\n",
    "    \n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+\n",
      "|  album|    genre|listeners|streams|rating|\n",
      "+-------+---------+---------+-------+------+\n",
      "|  roses|      rap|      351|   1138|     6|\n",
      "|jupiter|      rap|      135|   6518|    99|\n",
      "|   fire|     rock|      642|   2491|     7|\n",
      "|  venom|     rock|      786|   3714|    15|\n",
      "|    sky|classical|      124|   1142|    18|\n",
      "| danger|classical|      123|   6548|    99|\n",
      "|  ocean|classical|      368|   3528|    20|\n",
      "|   null|     null|      364|   3145|    17|\n",
      "|   null|     null|      420|   3528|    35|\n",
      "+-------+---------+---------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rename_cols_dict = {'listeners_imputed':'listeners',\n",
    "                    'streams_imputed':'streams',\n",
    "                    'rating_imputed':'rating'}\n",
    "\n",
    "for col in rename_cols_dict:\n",
    "    df_pyspark = df_pyspark.withColumnRenamed(col,rename_cols_dict[col])\n",
    "    \n",
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = df_pyspark.withColumn('streams_per_listener',df_pyspark['streams']/df_pyspark['listeners'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+--------------------+\n",
      "|  album|    genre|listeners|streams|rating|streams_per_listener|\n",
      "+-------+---------+---------+-------+------+--------------------+\n",
      "|jupiter|      rap|      135|   6518|    99|   48.28148148148148|\n",
      "| danger|classical|      123|   6548|    99|  53.235772357723576|\n",
      "|  ocean|classical|      368|   3528|    20|    9.58695652173913|\n",
      "|   null|     null|      420|   3528|    35|                 8.4|\n",
      "+-------+---------+---------+-------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter(df_pyspark['rating'] >= 20).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+---------+-------+------+--------------------+\n",
      "|album|    genre|listeners|streams|rating|streams_per_listener|\n",
      "+-----+---------+---------+-------+------+--------------------+\n",
      "|venom|     rock|      786|   3714|    15|  4.7251908396946565|\n",
      "|ocean|classical|      368|   3528|    20|    9.58695652173913|\n",
      "| null|     null|      364|   3145|    17|    8.64010989010989|\n",
      "| null|     null|      420|   3528|    35|                 8.4|\n",
      "+-----+---------+---------+-------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['rating'] >= 8) & (df_pyspark['listeners'] >= 140)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------+\n",
      "|album|listeners|rating|\n",
      "+-----+---------+------+\n",
      "|venom|      786|    15|\n",
      "|ocean|      368|    20|\n",
      "| null|      364|    17|\n",
      "| null|      420|    35|\n",
      "+-----+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.filter((df_pyspark['rating'] >= 8) & (df_pyspark['listeners'] >= 140)).select(['album',\n",
    "                                                                                          'listeners',\n",
    "                                                                                          'rating']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+------------+-----------+-------------------------+\n",
      "|    genre|sum(listeners)|sum(streams)|sum(rating)|sum(streams_per_listener)|\n",
      "+---------+--------------+------------+-----------+-------------------------+\n",
      "|     null|           784|        6673|         52|        17.04010989010989|\n",
      "|      rap|           486|        7656|        105|        51.52364672364672|\n",
      "|     rock|          1428|        6205|         22|        8.605253144990606|\n",
      "|classical|           615|       11218|        137|        72.03240629881755|\n",
      "+---------+--------------+------------+-----------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('genre').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+------------------+------------------+-------------------------+\n",
      "|    genre|avg(listeners)|      avg(streams)|       avg(rating)|avg(streams_per_listener)|\n",
      "+---------+--------------+------------------+------------------+-------------------------+\n",
      "|     null|         392.0|            3336.5|              26.0|        8.520054945054945|\n",
      "|      rap|         243.0|            3828.0|              52.5|        25.76182336182336|\n",
      "|     rock|         714.0|            3102.5|              11.0|        4.302626572495303|\n",
      "|classical|         205.0|3739.3333333333335|45.666666666666664|        24.01080209960585|\n",
      "+---------+--------------+------------------+------------------+-------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.groupBy('genre').mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+---------+-------+------+--------------------+--------------------+\n",
      "|  album|    genre|listeners|streams|rating|streams_per_listener|independent_features|\n",
      "+-------+---------+---------+-------+------+--------------------+--------------------+\n",
      "|  roses|      rap|      351|   1138|     6|   3.242165242165242|[351.0,1138.0,3.2...|\n",
      "|jupiter|      rap|      135|   6518|    99|   48.28148148148148|[135.0,6518.0,48....|\n",
      "|   fire|     rock|      642|   2491|     7|    3.88006230529595|[642.0,2491.0,3.8...|\n",
      "|  venom|     rock|      786|   3714|    15|  4.7251908396946565|[786.0,3714.0,4.7...|\n",
      "|    sky|classical|      124|   1142|    18|   9.209677419354838|[124.0,1142.0,9.2...|\n",
      "| danger|classical|      123|   6548|    99|  53.235772357723576|[123.0,6548.0,53....|\n",
      "|  ocean|classical|      368|   3528|    20|    9.58695652173913|[368.0,3528.0,9.5...|\n",
      "|   null|     null|      364|   3145|    17|    8.64010989010989|[364.0,3145.0,8.6...|\n",
      "|   null|     null|      420|   3528|    35|                 8.4|  [420.0,3528.0,8.4]|\n",
      "+-------+---------+---------+-------+------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureassembler = VectorAssembler(inputCols = ['listeners','streams','streams_per_listener'], outputCol = 'independent_features')\n",
    "\n",
    "output = featureassembler.transform(df_pyspark)\n",
    "\n",
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|independent_features|rating|\n",
      "+--------------------+------+\n",
      "|[351.0,1138.0,3.2...|     6|\n",
      "|[135.0,6518.0,48....|    99|\n",
      "|[642.0,2491.0,3.8...|     7|\n",
      "|[786.0,3714.0,4.7...|    15|\n",
      "|[124.0,1142.0,9.2...|    18|\n",
      "|[123.0,6548.0,53....|    99|\n",
      "|[368.0,3528.0,9.5...|    20|\n",
      "|[364.0,3145.0,8.6...|    17|\n",
      "|  [420.0,3528.0,8.4]|    35|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "regression_data = output.select(['independent_features', 'rating'])\n",
    "\n",
    "regression_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train_data, test_data = regression_data.randomSplit([0.75, 0.25])\n",
    "\n",
    "regressor = LinearRegression(featuresCol = 'independent_features', labelCol = 'rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([-0.0184, 0.006, 1.2081])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(regression_data).coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341156035419507"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(regression_data).intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+------------------+\n",
      "|independent_features|rating|        prediction|\n",
      "+--------------------+------+------------------+\n",
      "|[123.0,6548.0,53....|    99|106.54699934644592|\n",
      "|[351.0,1138.0,3.2...|     6|6.0863308997239685|\n",
      "|[642.0,2491.0,3.8...|     7| 10.45093473547274|\n",
      "+--------------------+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_results = regressor.fit(train_data).evaluate(test_data)\n",
    "pred_results.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22.957867569331512"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6947549938808746"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results.meanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
